{"version":"1","records":[{"hierarchy":{"lvl1":"ğŸ“Š Conclusion"},"type":"lvl1","url":"/conclusion","position":0},{"hierarchy":{"lvl1":"ğŸ“Š Conclusion"},"content":"This project demonstrates that data science is accessible and impactful across disciplines--from research and industry to government and community initiatives. By emphasizing hands-on experience, targeted prompts, and reproducible workflows, learners navigate their learning pathways through the attainment of task-specific badges that build toward meaningful data interpetation, problem solving, and critial thinking credentials. ğŸ§ ğŸ“ˆ\n\nNo prior coding is required to engage meaningfully with data science; and at its highest application learners gain and subsequently share core skills through open-sourced upskilling experiences that bridge the gap between technical barriers and real-world applications, empowering broader participation in the data-driven economy. ğŸŒâœ¨ Crucially, learners re-invest by sharing the results of their skills development, co-creating local open-science solutions, and advocating for equity. ğŸ“£ Amplifying community voice and resilience through algorithmic fluency. ğŸ”ğŸ¤–\n\nA key takeaway from our approach is that through AI-supported upskilling, learners can bridge the gap between technical barriers and real-world applications, empowering broader participation in the data-driven economy. ğŸš€ Most importantly, collective, open sourced content sharing can amplify community voice and resilience through algorithmic fluency. ğŸ”ğŸ’¬\n\nUltimately, this approach advocates for a democratized vision of data scienceâ€”where anyone can learn, practice, and contributeâ€”by fostering inclusive learning environments, sharing reproducible tools, and promoting AI-integrated pathways e.g. the AI Integration Specialist badge. ğŸ“ğŸ“šğŸ’¡","type":"content","url":"/conclusion","position":1},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/introduction","position":0},{"hierarchy":{"lvl1":"Introduction"},"content":"","type":"content","url":"/introduction","position":1},{"hierarchy":{"lvl1":"Introduction","lvl2":"ğŸŒ Enhancing Algorithmic Literacy Among Vulnerable Populations through Geoscience Applications"},"type":"lvl2","url":"/introduction#id-enhancing-algorithmic-literacy-among-vulnerable-populations-through-geoscience-applications","position":2},{"hierarchy":{"lvl1":"Introduction","lvl2":"ğŸŒ Enhancing Algorithmic Literacy Among Vulnerable Populations through Geoscience Applications"},"content":"Imagine a community-based geoscience project where local learners explore biodiversity through a dataset of penguin species.\n\nIn the geoscience community, algorithm literacy is more than technical fluencyâ€”itâ€™s a pathway to justice. Vulnerable populations often bear the brunt of environmental decisions shaped by opaque data systems. To shift this paradigm, we must equip these communities not only with knowledge, but with agency.\n\nğŸ¤– Enter the AI teammate: not as a distant tool, but as a responsive partner! Through explicit AI prompts, learners can engage in targeted, conversational learning that breaks down complex algorithmic concepts into accessible, actionable insights. These prompts serve as microburst upskilling lessonsâ€”short, focused interactions where AI explains concepts like correlations, classification, and feature importance in plain language.\n\nVulnerable populations, often excluded from technical discourse, now gain the tools to explore, question, and interpret data that mirrors real-world ecological systemsâ€”tailored to real-world geoscience challenges.\n\nBy embedding microburst upskilling into daily workflows and community initiatives, we create rapid, scalable opportunities for learning. These short, focused interactions with AI empower users to ask better questions, challenge assumptions, and co-create solutions. The result? A growing network of algorithm-literate individuals who can actively participate inâ€”and shapeâ€”their own liberation.\n\nLet us reimagine algorithm literacy not as a distant goal, but as a daily practice. With AI as a teammate and microburst learning as our method, we can build a geoscience future that is inclusive, transparent, and driven by the voices that matter most.","type":"content","url":"/introduction#id-enhancing-algorithmic-literacy-among-vulnerable-populations-through-geoscience-applications","position":3},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook"},"content":"Tiffany Boyer - Contributor; Dr. Francis Tuluri - Contributor; and Temilouwa - Contributor; Connor Quiroz - Lead","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"âœï¸ Authors"},"type":"lvl2","url":"/#id-authors","position":2},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"âœï¸ Authors"},"content":"Authors: \n\nTemiloluwa Adesola; \n\nTiffany Boyer; \n\nDr. Francis Tuluri, PhD; Lead Author, \n\nConnor Quiroz","type":"content","url":"/#id-authors","position":3},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Acknowledgements"},"type":"lvl2","url":"/#acknowledgements","position":4},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Acknowledgements"},"content":"James Munroe for providing input on project ideation and providing next step guidance for integrating an AI interface in our cookbook.","type":"content","url":"/#acknowledgements","position":5},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"ğŸ™Œ Contributors","lvl2":"Acknowledgements"},"type":"lvl3","url":"/#id-contributors","position":6},{"hierarchy":{"lvl1":"ğŸ“˜ A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"ğŸ™Œ Contributors","lvl2":"Acknowledgements"},"content":"\n\n \n\n\n\n\n\n\n\n","type":"content","url":"/#id-contributors","position":7},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/abstract","position":0},{"hierarchy":{"lvl1":""},"content":"Abstract\n\nğŸŒ This Project Pythia Cookbook covers how geoscience enables algorithmic literacy through AI-guided microburst learning.\n\nIn this application, learners gain core skills and confidence, earning badges toward data credentials.\n\nMost importantly, they reinvest by mentoring peers, co-creating local data solutions, and advocating for equitable systemsâ€”amplifying community voice and resilience through algorithmic fluency.","type":"content","url":"/abstract","position":1},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization"},"type":"lvl1","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual","position":0},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual","position":1},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"AI-Powered Data Cleaning & Visualization with Palmer Penguins"},"type":"lvl3","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#ai-powered-data-cleaning-visualization-with-palmer-penguins","position":2},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"AI-Powered Data Cleaning & Visualization with Palmer Penguins"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#ai-powered-data-cleaning-visualization-with-palmer-penguins","position":3},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ§ Welcome to your AI Integration Journey!","lvl3":"AI-Powered Data Cleaning & Visualization with Palmer Penguins"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-welcome-to-your-ai-integration-journey","position":4},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ§ Welcome to your AI Integration Journey!","lvl3":"AI-Powered Data Cleaning & Visualization with Palmer Penguins"},"content":"This section demonstrates how AI can enhance every step of your data science workflow, from initial data cleaning to creating compelling visualizations. Youâ€™ll learn the WHAT, HOW, and WHY of integrating AI into your data science process.\n\nBy the end of this section, youâ€™ll understand:\n\nHow to collaborate with AI for data exploration\n\nAI-assisted data cleaning techniques\n\nCreating publication-ready visualizations with AI guidance\n\nBest practices for human-AI collaboration in data science","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-welcome-to-your-ai-integration-journey","position":5},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"type":"lvl3","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-the-what-how-and-why-of-ai-integration","position":6},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-the-what-how-and-why-of-ai-integration","position":7},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ“– WHAT: Understanding AI in Data Science","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-what-understanding-ai-in-data-science","position":8},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ“– WHAT: Understanding AI in Data Science","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"content":"Important: AI integration in data science isnâ€™t about replacing human expertiseâ€”itâ€™s about amplifying your capabilities. Think of AI as your intelligent collaborator that brings:\n\nğŸ” Smart Research Assistant: Helps explore data patterns\n\nğŸ§¹ Intelligent Cleaner: Identifies and handles data quality issues\n\nğŸ¨ Visualization Designer: Suggests optimal chart types and styling\n\nğŸ¤– Pattern Detective: Reveals hidden insights in your data","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-what-understanding-ai-in-data-science","position":9},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"Key Integration Points:","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#key-integration-points","position":10},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"Key Integration Points:","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"content":"Data Loading & Initial Exploration\n\nMissing Value Detection & Treatment\n\nOutlier Analysis & Handling\n\nVisualization Strategy & Implementation\n\nInsight Generation & Interpretation\n\nPrompts we gave to the AI chat\n\nChoose a chatbot of your choice (e.g., ChatGPT, Claude, Copilot, Gemini) to begin typing prompts for your data science project. Here are examples we used to clean and visualize our data:\n\nUsing GitHub, load the Palmer Penguins dataset and display the variable names. Let me create a Python script that does this.\n\nGIVEN these variables in the dataset, can you create 3 plots useful for differentiating these species that use only five of the variables? Use only pandas, matplotlib, and plotly.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.io as pio\nimport seaborn as sns\nfrom IPython.display import display, HTML\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set up plotting preferences\nplt.style.use('seaborn-v0_8-whitegrid')\npio.templates.default = \"plotly_white\"\n\nprint(\"ğŸ“š Libraries loaded successfully!\")\n\ndef load_penguin_data_with_ai_insights():\n    \"\"\"\n    AI-Enhanced data loading function that provides immediate insights\n    \"\"\"\n    try:\n        # GitHub URL for the CSV file (raw format)\n        url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n        \n        print(\"ğŸ“¥ Loading Palmer Penguins dataset...\")\n        penguins = pd.read_csv(url)\n        \n        # AI-generated immediate insights\n        print(f\"âœ… Successfully loaded {len(penguins)} penguin observations\")\n        print(f\"ğŸ“Š Dataset contains {penguins.shape[1]} variables\")\n        print(f\"ğŸï¸  Data collected from {penguins['island'].nunique()} islands\")\n        print(f\"ğŸ§ Includes {penguins['species'].nunique()} penguin species\")\n        print(f\"ğŸ“… Covers years {penguins['year'].min()}-{penguins['year'].max()}\")\n        \n        return penguins\n        \n    except Exception as e:\n        print(f\"âŒ Error loading data: {e}\")\n        print(\"ğŸ’¡ AI Suggestion: Check internet connection and URL accessibility\")\n        return None\n\n# Execute AI-enhanced data loading\npenguins = load_penguin_data_with_ai_insights()\n\n","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#key-integration-points","position":11},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ’¡ Why This Approach Works:","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-why-this-approach-works","position":12},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ’¡ Why This Approach Works:","lvl3":"ğŸ¯ The WHAT, HOW, and WHY of AI Integration"},"content":"Notice how weâ€™re not just loading dataâ€”weâ€™re immediately getting contextual insights that inform our next steps. The AI helps us understand the scope and structure before we dive deeper.\n\ndef generate_ai_data_profile(df):\nâ€œâ€\"\nAI-enhanced data profiling that goes beyond basic statistics\nâ€œâ€\"\nprint(â€œğŸ” AI-Generated Data Profile Reportâ€)\nprint(â€œ=â€ * 40)# Basic structure\nprint(f\"ğŸ“‹ Dataset Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\nprint(f\"ğŸ’¾ Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\nprint()\n\n# Variable types analysis\nprint(\"ğŸ“Š Variable Type Analysis:\")\ndtype_counts = df.dtypes.value_counts()\nfor dtype, count in dtype_counts.items():\n    print(f\"   â€¢ {dtype}: {count} variables\")\nprint()\n\n# Missing data analysis\nmissing_data = df.isnull().sum()\nmissing_pct = (missing_data / len(df)) * 100\n\nprint(\"ğŸ” Missing Data Analysis:\")\nif missing_data.sum() == 0:\n    print(\"   âœ… No missing values detected!\")\nelse:\n    print(\"   âš ï¸  Missing values found:\")\n    for col in missing_data[missing_data > 0].index:\n        print(f\"      â€¢ {col}: {missing_data[col]} ({missing_pct[col]:.1f}%)\")\nprint()\n\n# Data quality flags - AI-powered quality assessment\nprint(\"ğŸš© AI Data Quality Flags:\")\nquality_flags = []\n\n# Check for potential duplicates\nduplicate_count = df.duplicated().sum()\nif duplicate_count > 0:\n    quality_flags.append(f\"Potential duplicates: {duplicate_count}\")\n\n# Check for outliers in numeric columns\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\nfor col in numeric_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    outliers = len(df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)])\n    if outliers > 0:\n        quality_flags.append(f\"{col}: {outliers} potential outliers\")\n\nif quality_flags:\n    for flag in quality_flags:\n        print(f\"   âš ï¸  {flag}\")\nelse:\n    print(\"   âœ… No major quality issues detected\")\n\nreturn missing_data, missing_pct","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-why-this-approach-works","position":13},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl2":"Generate AI data profile"},"type":"lvl2","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#generate-ai-data-profile","position":14},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl2":"Generate AI data profile"},"content":"missing_summary, missing_percentages = generate_ai_data_profile(penguins)\n\n# Display the data structure\nprint(\"ğŸ“‹ Dataset Structure:\")\nprint(\"-\" * 20)\ndisplay(penguins.head(10))\nprint()\n\nprint(\"ğŸ·ï¸ Variable Definitions:\")\nprint(\"-\" * 25)\nvariable_definitions = {\n    'species': 'Penguin species (Adelie, Chinstrap, Gentoo)',\n    'island': 'Island where observed (Biscoe, Dream, Torgersen)', \n    'bill_length_mm': 'Bill length measurement in millimeters',\n    'bill_depth_mm': 'Bill depth measurement in millimeters',\n    'flipper_length_mm': 'Flipper length measurement in millimeters',\n    'body_mass_g': 'Body mass measurement in grams',\n    'sex': 'Penguin sex (male, female)',\n    'year': 'Year of observation (2007-2009)'\n}\n\nfor var, definition in variable_definitions.items():\n    print(f\"â€¢ {var}: {definition}\")\n\n","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#generate-ai-data-profile","position":15},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"type":"lvl3","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ai-assisted-data-cleaning","position":16},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ai-assisted-data-cleaning","position":17},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-how-we-engage-ai-for-intelligent-cleaning","position":18},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-how-we-engage-ai-for-intelligent-cleaning","position":19},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl5":"ğŸ’¬ Effective AI Prompting for Data Cleaning","lvl4":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"type":"lvl5","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-effective-ai-prompting-for-data-cleaning","position":20},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl5":"ğŸ’¬ Effective AI Prompting for Data Cleaning","lvl4":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"content":"Instead of: â€œClean my dataâ€Try: â€œAnalyze the missing data patterns and recommend a cleaning strategy that balances data retention with model performance for a penguin species classification taskâ€\n\nWhy it works: We provide context (classification task), constraints (data retention vs performance), and specific guidance (missing data patterns).\n\nKey Insight: The key to AI-assisted cleaning is providing domain context and analytical objectives\n\ndef ai_assisted_data_cleaning(df):\n    \"\"\"\n    AI-guided data cleaning with explanations for each step\n    \"\"\"\n    print(\"ğŸ§¹ AI Data Cleaning Assistant Activated\")\n    print(\"=\" * 42)\n    \n    # Create a copy for cleaning\n    clean_df = df.copy()\n    original_rows = len(clean_df)\n    \n    print(f\"ğŸ“Š Starting with {original_rows:,} observations\")\n    print()\n    \n    # Step 1: Missing value analysis and treatment\n    print(\"Step 1: ğŸ” Missing Value Analysis\")\n    print(\"-\" * 35)\n    \n    missing_counts = clean_df.isnull().sum()\n    if missing_counts.sum() > 0:\n        print(\"Missing values detected:\")\n        for col in missing_counts[missing_counts > 0].index:\n            count = missing_counts[col]\n            pct = (count / len(clean_df)) * 100\n            print(f\"  â€¢ {col}: {count} values ({pct:.1f}%)\")\n        \n        print(\"\\nğŸ¤– AI Recommendation: Remove rows with ANY missing values\")\n        print(\"   Rationale: For classification tasks, complete cases provide\")\n        print(\"   the most reliable training data. Small dataset allows this approach.\")\n        \n        # Apply cleaning\n        clean_df = clean_df.dropna()\n        removed_rows = original_rows - len(clean_df)\n        print(f\"\\nâœ… Removed {removed_rows} rows with missing values\")\n        print(f\"ğŸ“Š Clean dataset: {len(clean_df):,} observations\")\n    else:\n        print(\"âœ… No missing values found!\")\n    \n    print()\n    \n    # Step 2: Data type optimization\n    print(\"Step 2: ğŸ”§ Data Type Optimization\") \n    print(\"-\" * 35)\n    \n    # Convert categorical variables\n    categorical_vars = ['species', 'island', 'sex']\n    for var in categorical_vars:\n        if var in clean_df.columns:\n            clean_df[var] = clean_df[var].astype('category')\n            print(f\"  â€¢ {var}: converted to categorical\")\n    \n    print(\"âœ… Data types optimized for memory efficiency\")\n    print()\n    \n    # Step 3: Outlier detection\n    print(\"Step 3: ğŸ¯ Outlier Analysis\")\n    print(\"-\" * 35)\n    \n    numeric_cols = clean_df.select_dtypes(include=[np.number]).columns\n    outlier_summary = {}\n    \n    for col in numeric_cols:\n        if col != 'year':  # Skip year column\n            Q1 = clean_df[col].quantile(0.25)\n            Q3 = clean_df[col].quantile(0.75)\n            IQR = Q3 - Q1\n            lower_bound = Q1 - 1.5 * IQR\n            upper_bound = Q3 + 1.5 * IQR\n            \n            outliers = clean_df[(clean_df[col] < lower_bound) | \n                              (clean_df[col] > upper_bound)]\n            \n            outlier_summary[col] = len(outliers)\n            \n            if len(outliers) > 0:\n                print(f\"  â€¢ {col}: {len(outliers)} potential outliers\")\n            else:\n                print(f\"  âœ… {col}: No outliers detected\")\n    \n    print(\"\\nğŸ¤– AI Recommendation: Keep outliers for biological diversity\")\n    print(\"   Rationale: In biological data, extreme values often represent\")\n    print(\"   natural variation rather than measurement errors.\")\n    print()\n    \n    # Final summary\n    print(\"ğŸ“‹ Cleaning Summary:\")\n    print(\"-\" * 20)\n    print(f\"Original rows: {original_rows:,}\")\n    print(f\"Final rows: {len(clean_df):,}\")\n    print(f\"Data retention: {(len(clean_df)/original_rows)*100:.1f}%\")\n    \n    return clean_df, outlier_summary\n\n# Execute AI-assisted cleaning\nclean_penguins, outlier_info = ai_assisted_data_cleaning(penguins)\n\n","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-effective-ai-prompting-for-data-cleaning","position":21},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ§  AI Cleaning Philosophy","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ai-cleaning-philosophy","position":22},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ§  AI Cleaning Philosophy","lvl3":"ğŸ§¹ AI-Assisted Data Cleaning","lvl2":"Generate AI data profile"},"content":"Notice how the AI provides not just actions, but rationale for each decision. This builds trust and understanding, making the process educational rather than just automated.","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ai-cleaning-philosophy","position":23},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ¨ AI-Enhanced Data Visualization","lvl2":"Generate AI data profile"},"type":"lvl3","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ai-enhanced-data-visualization","position":24},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ¨ AI-Enhanced Data Visualization","lvl2":"Generate AI data profile"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ai-enhanced-data-visualization","position":25},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl3":"ğŸ¨ AI-Enhanced Data Visualization","lvl2":"Generate AI data profile"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-engaging-ai-for-strategic-visualization-planning","position":26},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl3":"ğŸ¨ AI-Enhanced Data Visualization","lvl2":"Generate AI data profile"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-engaging-ai-for-strategic-visualization-planning","position":27},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl5":"ğŸ’¬ How to Ask AI for Visualization Strategy","lvl4":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl3":"ğŸ¨ AI-Enhanced Data Visualization","lvl2":"Generate AI data profile"},"type":"lvl5","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-how-to-ask-ai-for-visualization-strategy","position":28},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl5":"ğŸ’¬ How to Ask AI for Visualization Strategy","lvl4":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl3":"ğŸ¨ AI-Enhanced Data Visualization","lvl2":"Generate AI data profile"},"content":"Instead of: â€œMake some chartsâ€Try: â€œGiven that I have a classification problem with 3 species and 4 numerical features, what visualization strategy would best reveal class separability and feature relationships?â€\n\nResult: AI provides a strategic framework rather than random charts.\n\ndef ai_visualization_strategy(df):\n    \"\"\"\n    AI-powered visualization recommendations based on data characteristics\n    \"\"\"\n    print(\"ğŸ¨ AI Visualization Strategist\")\n    print(\"=\" * 32)\n    \n    # Analyze data characteristics\n    n_categorical = len(df.select_dtypes(include=['category', 'object']).columns)\n    n_numerical = len(df.select_dtypes(include=[np.number]).columns) - 1  # Exclude year\n    n_observations = len(df)\n    \n    print(f\"ğŸ“Š Data Profile: {n_observations} obs, {n_categorical} categorical, {n_numerical} numerical variables\")\n    print()\n    \n    print(\"ğŸ¯ AI-Recommended Visualization Strategy:\")\n    print(\"-\" * 42)\n    \n    recommendations = [\n        {\n            'viz_type': 'Species Distribution Analysis',\n            'purpose': 'Understand class balance in our target variable',\n            'ai_rationale': 'Essential for classification - reveals potential class imbalance issues'\n        },\n        {\n            'viz_type': 'Bivariate Relationship Exploration', \n            'purpose': 'Discover feature relationships and species separation',\n            'ai_rationale': 'Scatter plots reveal natural clustering and decision boundaries'\n        },\n        {\n            'viz_type': 'Feature Distribution Comparison',\n            'purpose': 'Compare distributions across species',\n            'ai_rationale': 'Box plots show central tendency and variability for each group'\n        },\n        {\n            'viz_type': 'Correlation Heatmap',\n            'purpose': 'Identify multicollinearity and feature relationships',\n            'ai_rationale': 'Critical for feature selection and model interpretation'\n        }\n    ]\n    \n    for i, rec in enumerate(recommendations, 1):\n        print(f\"{i}. {rec['viz_type']}\")\n        print(f\"   Purpose: {rec['purpose']}\")\n        print(f\"   ğŸ¤– AI Rationale: {rec['ai_rationale']}\")\n        print()\n    \n    return recommendations\n\n# Get AI visualization strategy\nviz_strategy = ai_visualization_strategy(clean_penguins)\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Count species\nspecies_counts = clean_penguins['species'].value_counts()\nspecies = species_counts.index.tolist()\ncounts = species_counts.values\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n\n# Create subplot layout with 1 row, 2 columns\nfig = make_subplots(rows=1, cols=2, \n                    subplot_titles=(\"Penguin Species Distribution\", \"Species Proportion\"),\n                    specs=[[{\"type\": \"bar\"}, {\"type\": \"domain\"}]])\n\n# Bar chart\nfig.add_trace(\n    go.Bar(\n        x=species,\n        y=counts,\n        text=counts,\n        textposition='outside',\n        marker_color=colors,\n        name=\"Count\"\n    ),\n    row=1, col=1\n)\n\n# Pie chart\nfig.add_trace(\n    go.Pie(\n        labels=species,\n        values=counts,\n        marker_colors=colors,\n        name=\"Proportion\",\n        hole=0,\n        textinfo='label+percent'\n    ),\n    row=1, col=2\n)\n\n# Update layout\nfig.update_layout(\n    height=500,\n    width=900,\n    title_text=\"ğŸ“Š Visualization 1: Species Distribution Analysis\",\n    title_font_size=18,\n    showlegend=False,\n    margin=dict(t=80)\n)\n\nfig.show()\n\n# Print AI-Generated Insights\nprint(f\"\\nğŸ¤– AI-Generated Insights:\")\ntotal = len(clean_penguins)\nfor sp in species:\n    count = species_counts[sp]\n    percentage = count / total * 100\n    print(f\"â€¢ {sp}: {count} penguins ({percentage:.1f}%)\")\n\n\nimport plotly.express as px\nimport plotly.subplots as sp\nimport plotly.graph_objects as go\n\n# Relationships to explore\nrelationships = [\n    ('bill_length_mm', 'bill_depth_mm'),\n    ('bill_length_mm', 'flipper_length_mm'),\n    ('flipper_length_mm', 'body_mass_g'),\n    ('bill_depth_mm', 'body_mass_g')\n]\n\n# Color mapping\ncolors = {'Adelie': '#FF6B6B', 'Chinstrap': '#4ECDC4', 'Gentoo': '#45B7D1'}\n\n# Create subplot grid: 2 rows, 2 columns\nfig = sp.make_subplots(rows=2, cols=2,\n                       subplot_titles=[f'{x.replace(\"_\", \" \").title()} vs {y.replace(\"_\", \" \").title()}' \n                                       for x, y in relationships])\n\n# Add scatter traces for each relationship and species\nfor idx, (x_var, y_var) in enumerate(relationships):\n    row = idx // 2 + 1\n    col = idx % 2 + 1\n\n    for species in clean_penguins['species'].unique():\n        species_data = clean_penguins[clean_penguins['species'] == species]\n\n        fig.add_trace(\n            go.Scatter(\n                x=species_data[x_var],\n                y=species_data[y_var],\n                mode='markers',\n                name=species if idx == 0 else None,  # Show legend only once\n                marker=dict(color=colors[species], size=8, opacity=0.7),\n                legendgroup=species,\n                showlegend=(idx == 0),\n                hovertemplate=f'<b>{species}</b><br>{x_var}: %{{x}}<br>{y_var}: %{{y}}<extra></extra>'\n            ),\n            row=row, col=col\n        )\n\n# Update layout\nfig.update_layout(\n    height=800,\n    width=1000,\n    title_text=\"ğŸ“Š AI-Recommended Feature Relationships by Species\",\n    title_font=dict(size=18, family='Arial', color='black'),\n    plot_bgcolor='white',\n    legend_title_text='Species',\n    margin=dict(t=80)\n)\n\n# Update axis titles\nfor idx, (x_var, y_var) in enumerate(relationships):\n    row = idx // 2 + 1\n    col = idx % 2 + 1\n    fig.update_xaxes(title_text=x_var.replace('_', ' ').title(), row=row, col=col, showgrid=True, gridcolor='lightgray')\n    fig.update_yaxes(title_text=y_var.replace('_', ' ').title(), row=row, col=col, showgrid=True, gridcolor='lightgray')\n\n# Show figure\nfig.show()\n\n# Print pattern recognition notes\nprint(\"\\nğŸ¤– AI Pattern Recognition:\")\nprint(\"â€¢ Clear species clustering visible in multiple feature combinations\")\nprint(\"â€¢ Excellent linear separability suggests high classification accuracy potential\")\nprint(\"â€¢ Flipper length vs body mass shows strongest species separation\")\n\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nprint(\"ğŸ“Š Visualization 3: Feature Distribution Comparison\")\nprint(\"-\" * 52)\n\n# Variables and color setup\nnumerical_vars = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\nspecies_categories = clean_penguins['species'].cat.categories\ncolors = {'Adelie': '#FF6B6B', 'Chinstrap': '#4ECDC4', 'Gentoo': '#45B7D1'}\n\n# Create 2x2 subplot grid\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=[var.replace('_', ' ').title() for var in numerical_vars],\n    horizontal_spacing=0.15,\n    vertical_spacing=0.2\n)\n\n# Add box plots\nfor idx, var in enumerate(numerical_vars):\n    row = idx // 2 + 1\n    col = idx % 2 + 1\n    for species in species_categories:\n        fig.add_trace(\n            go.Box(\n                x=[species] * len(clean_penguins[clean_penguins['species'] == species]),\n                y=clean_penguins[clean_penguins['species'] == species][var],\n                name=species,\n                boxmean=True,\n                width=0.4,  # Wider box\n                marker_color=colors[species],\n                legendgroup=species,\n                showlegend=(idx == 0),  # Show legend only once\n                line=dict(width=1),\n                opacity=0.7\n            ),\n            row=row, col=col\n        )\n    # Lock x-axis category order for consistency\n    fig.update_xaxes(\n        categoryorder='array',\n        categoryarray=list(species_categories),\n        title_text=\"Species\",\n        row=row, col=col\n    )\n\n    fig.update_yaxes(title_text=\"Value\", row=row, col=col)\n\n# Layout tweaks\nfig.update_layout(\n    height=800,\n    width=1000,\n    title_text=\"ğŸ“Š Feature Distributions by Species\",\n    title_font=dict(size=18, family='Arial', color='black'),\n    margin=dict(t=80),\n    boxmode='group'\n)\n\nfig.show()\n\n# AI-generated insights\nprint(\"\\nğŸ¤– AI Species Profiling:\")\nprint(\"â€¢ Adelie: Shorter bills, deeper bills, smaller overall size\")\nprint(\"â€¢ Chinstrap: Longest bills, medium size\")\nprint(\"â€¢ Gentoo: Longest flippers, largest body mass\")\nprint(\"â€¢ Clear discriminative patterns identified for classification\")\n\nprint(\"ğŸ“Š Visualization 4: Interactive Feature Explorer\")\nprint(\"-\" * 50)\n\n# Create interactive scatter plot\nfig = px.scatter(clean_penguins,\n                x='flipper_length_mm',\n                y='body_mass_g',\n                color='species',\n                size='bill_length_mm',\n                hover_data=['bill_depth_mm', 'island', 'sex'],\n                title='Interactive Penguin Feature Explorer',\n                color_discrete_map={'Adelie': '#FF6B6B', \n                                   'Chinstrap': '#4ECDC4', \n                                   'Gentoo': '#45B7D1'})\n\nfig.update_layout(\n    height=600,\n    title_font_size=16,\n    xaxis_title=\"Flipper Length (mm)\",\n    yaxis_title=\"Body Mass (g)\"\n)\n\n# Display the plot\nfig.show()\n\nprint(\"\\nğŸ¤– Interactive Analysis Complete!\")\nprint(\"â€¢ Hover over points to explore individual penguin characteristics\")\nprint(\"â€¢ Notice the clear species clustering in flipper-mass space\")\nprint(\"â€¢ Bill length (bubble size) correlates strongly with body mass\")\n\n","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-how-to-ask-ai-for-visualization-strategy","position":29},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ† Key Takeaways and Next Steps","lvl2":"Generate AI data profile"},"type":"lvl3","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-key-takeaways-and-next-steps","position":30},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸ† Key Takeaways and Next Steps","lvl2":"Generate AI data profile"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-key-takeaways-and-next-steps","position":31},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ¯ What Youâ€™ve Accomplished","lvl3":"ğŸ† Key Takeaways and Next Steps","lvl2":"Generate AI data profile"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-what-youve-accomplished","position":32},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ¯ What Youâ€™ve Accomplished","lvl3":"ğŸ† Key Takeaways and Next Steps","lvl2":"Generate AI data profile"},"content":"âœ… Your AI Integration Achievements:\n\nMastered AI-enhanced data loading with immediate insights\n\nGenerated comprehensive data profiles using AI assistance\n\nImplemented intelligent data cleaning with AI recommendations\n\nCreated strategic visualizations guided by AI analysis\n\nDiscovered key patterns that will drive successful classification","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-what-youve-accomplished","position":33},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ§  Key AI Integration Principles","lvl3":"ğŸ† Key Takeaways and Next Steps","lvl2":"Generate AI data profile"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-key-ai-integration-principles","position":34},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ§  Key AI Integration Principles","lvl3":"ğŸ† Key Takeaways and Next Steps","lvl2":"Generate AI data profile"},"content":"ğŸ¤ Collaboration over Replacement - AI amplifies human expertise rather than replacing it\n\nğŸ“Š Data-Driven Decisions - Let AI analyze patterns, humans interpret context\n\nğŸ”„ Iterative Improvement - Use AI feedback to refine your approach\n\nğŸ“ˆ Scalable Methods - Develop reusable AI-assisted workflows\n\nğŸ¯ Goal-Oriented - Align AI assistance with business objectives","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-key-ai-integration-principles","position":35},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸš€ Ready for Mission Assignment 2: Prediction & Machine Learning","lvl2":"Generate AI data profile"},"type":"lvl3","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ready-for-mission-assignment-2-prediction-machine-learning","position":36},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl3":"ğŸš€ Ready for Mission Assignment 2: Prediction & Machine Learning","lvl2":"Generate AI data profile"},"content":"","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-ready-for-mission-assignment-2-prediction-machine-learning","position":37},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ–ï¸ Achievement Unlocked!","lvl3":"ğŸš€ Ready for Mission Assignment 2: Prediction & Machine Learning","lvl2":"Generate AI data profile"},"type":"lvl4","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-achievement-unlocked","position":38},{"hierarchy":{"lvl1":"Mission Assignment 1 - Data Cleaning and Data Visualization","lvl4":"ğŸ–ï¸ Achievement Unlocked!","lvl3":"ğŸš€ Ready for Mission Assignment 2: Prediction & Machine Learning","lvl2":"Generate AI data profile"},"content":"Congratulations! You completed Data Cleaning and Visualization!\n\nIn the next section, youâ€™ll learn to:\n\nBuild and train classification models with AI guidance\n\nOptimize model performance using AI recommendations\n\nDeploy your trained models for real-world predictions\n\nEvaluate and interpret results with AI assistance\n\nNote: Continue to Section 2 to become an â€˜AI Model Builderâ€™ and complete your journey to AI Integration Expert!\n\n# Save cleaned data for next section\nclean_penguins.to_csv('cleaned_penguins_data.csv', index=False)\nprint(\"ğŸ’¾ Cleaned dataset saved as 'cleaned_penguins_data.csv' for Section 2\")\nprint(f\"ğŸ“Š Final dataset contains {len(clean_penguins)} observations\")\nprint(\"ğŸš€ Ready to proceed to AI Model Building!\")","type":"content","url":"/notebooks/mission-assignment-1-data-cleaning-and-data-visual#id-achievement-unlocked","position":39},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning"},"type":"lvl1","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni","position":0},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni","position":1},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"AI-Powered Prediction & Machine Learning with Palmer Penguins"},"type":"lvl2","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#ai-powered-prediction-machine-learning-with-palmer-penguins","position":2},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"AI-Powered Prediction & Machine Learning with Palmer Penguins"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#ai-powered-prediction-machine-learning-with-palmer-penguins","position":3},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– From Visualization to Prediction: Your Next AI Journey!","lvl2":"AI-Powered Prediction & Machine Learning with Palmer Penguins"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-from-visualization-to-prediction-your-next-ai-journey","position":4},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– From Visualization to Prediction: Your Next AI Journey!","lvl2":"AI-Powered Prediction & Machine Learning with Palmer Penguins"},"content":"This chapter demonstrates how AI can take you beyond descriptive analytics into the powerful world of predictive modeling. Youâ€™ll learn to build machine learning models that donâ€™t just show you what happenedâ€”they predict what will happen next.\n\nBy the end of this chapter, youâ€™ll understand:\n\nHow to transition from visualization to prediction with AI assistance\n\nBuilding your first machine learning classifier\n\nEvaluating model performance and understanding predictions\n\nBest practices for AI-assisted machine learning workflows","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-from-visualization-to-prediction-your-next-ai-journey","position":5},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"type":"lvl2","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-the-what-how-and-why-of-predictive-ai","position":6},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-the-what-how-and-why-of-predictive-ai","position":7},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ“– WHAT: Understanding Machine Learning in Your Workflow","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-what-understanding-machine-learning-in-your-workflow","position":8},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ“– WHAT: Understanding Machine Learning in Your Workflow","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"content":"Key Insight: Machine learning is the natural next step after data visualization. While charts show you patterns in historical data, ML models learn those patterns to make predictions about new, unseen data.\n\nThink of AI-powered machine learning as your intelligent pattern recognition system that brings:\n\nğŸ§  Pattern Learner: Identifies complex relationships in your data\n\nğŸ”® Future Predictor: Makes informed predictions about new cases\n\nâš–ï¸ Decision Assistant: Provides confidence scores and reasoning\n\nğŸ¯ Performance Monitor: Evaluates and improves prediction accuracy","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-what-understanding-machine-learning-in-your-workflow","position":9},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"Key Machine Learning Integration Points:","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#key-machine-learning-integration-points","position":10},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"Key Machine Learning Integration Points:","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"content":"Data Preprocessing & Feature Engineering\n\nModel Selection & Training\n\nPrediction Generation & Validation\n\nPerformance Evaluation & Interpretation\n\nModel Deployment & Monitoring\n\nPrompts we gave to the AI chat\n\nI am a environmental and data scientist. Use the penguin data set, and give python script for penguin classification in jupyter notebookes\n\nimport pandas as pd\n\n# GitHub URL for the CSV file (raw format)\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n\n# Load the dataset into a pandas DataFrame\npenguins = pd.read_csv(url)\n\n# Display the variable (column) names\nprint(\"Variable (column) names in the Palmer Penguins dataset:\")\nprint(penguins.columns.tolist())\n\npip install plotly\n\nimport plotly\n\nimport pandas as pd\n\n# GitHub URL for the CSV file (raw format)\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n\n# Load the dataset into a pandas DataFrame\npenguins = pd.read_csv(url)\n\n# Display the variable (column) names\nprint(\"Variable (column) names in the Palmer Penguins dataset:\")\nprint(penguins.columns.tolist())\n\n\nprint(penguins.head(10))\n\n","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#key-machine-learning-integration-points","position":11},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ’¡ Why This Approach Works:","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-why-this-approach-works","position":12},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ’¡ Why This Approach Works:","lvl2":"ğŸ¯ The WHAT, HOW, and WHY of Predictive AI"},"content":"Notice how weâ€™re not just loading dataâ€”weâ€™re immediately getting contextual insights that inform our next steps. The AI helps us understand the scope and structure before we dive deeper.\n\n","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-why-this-approach-works","position":13},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"type":"lvl2","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-assisted-data-cleaning","position":14},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-assisted-data-cleaning","position":15},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-how-we-engage-ai-for-intelligent-cleaning","position":16},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-how-we-engage-ai-for-intelligent-cleaning","position":17},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl4":"ğŸ’¬ Effective AI Prompting for Data Cleaning","lvl3":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"type":"lvl4","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-effective-ai-prompting-for-data-cleaning","position":18},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl4":"ğŸ’¬ Effective AI Prompting for Data Cleaning","lvl3":"ğŸ¤– How We Engage AI for Intelligent Cleaning","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"content":"Instead of: â€œClean my dataâ€Try: â€œAnalyze the missing data patterns and recommend a cleaning strategy that balances data retention with model performance for a penguin species classification taskâ€\n\nWhy it works: We provide context (classification task), constraints (data retention vs performance), and specific guidance (missing data patterns).\n\nKey Insight: The key to AI-assisted cleaning is providing domain context and analytical objectives\n\ncolumn_names_list = penguins.columns.tolist()\nprint(\"Column names (as a list using .tolist()):\")\nprint(column_names_list)\n\n\n","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-effective-ai-prompting-for-data-cleaning","position":19},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ§  AI Cleaning Philosophy","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-cleaning-philosophy","position":20},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ§  AI Cleaning Philosophy","lvl2":"ğŸ§¹ AI-Assisted Data Cleaning"},"content":"Notice how the AI provides not just actions, but rationale for each decision. This builds trust and understanding, making the process educational rather than just automated.","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-cleaning-philosophy","position":21},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl2","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-enhanced-data-visualization","position":22},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-enhanced-data-visualization","position":23},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-engaging-ai-for-strategic-visualization-planning","position":24},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-engaging-ai-for-strategic-visualization-planning","position":25},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl4":"ğŸ’¬ How to Ask AI for Visualization Strategy","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl4","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-how-to-ask-ai-for-visualization-strategy","position":26},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl4":"ğŸ’¬ How to Ask AI for Visualization Strategy","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"Instead of: â€œMake some chartsâ€Try: â€œGiven that I have a classification problem with 3 species and 4 numerical features, what visualization strategy would best reveal class separability and feature relationships?â€\n\nResult: AI provides a strategic framework rather than random charts.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load dataset\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\n\n# Drop rows with missing values in selected columns\npenguins = penguins[['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].dropna()\n\n# Set style\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# 1. Scatter Plot: Bill Length vs Bill Depth\nplt.figure(figsize=(8, 6))\nfor species in penguins['species'].unique():\n    subset = penguins[penguins['species'] == species]\n    plt.scatter(subset['bill_length_mm'], subset['bill_depth_mm'], label=species, alpha=0.7)\nplt.xlabel(\"Bill Length (mm)\")\nplt.ylabel(\"Bill Depth (mm)\")\nplt.title(\"Bill Length vs Bill Depth by Species\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# 2. Box Plot: Flipper Length by Species\nplt.figure(figsize=(8, 6))\npenguins.boxplot(column='flipper_length_mm', by='species')\nplt.title(\"Flipper Length by Species\")\nplt.suptitle('')\nplt.xlabel(\"Species\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.tight_layout()\nplt.show()\n\n# 3. Scatter Plot: Flipper Length vs Body Mass\nplt.figure(figsize=(8, 6))\nfor species in penguins['species'].unique():\n    subset = penguins[penguins['species'] == species]\n    plt.scatter(subset['flipper_length_mm'], subset['body_mass_g'], label=species, alpha=0.7)\nplt.xlabel(\"Flipper Length (mm)\")\nplt.ylabel(\"Body Mass (g)\")\nplt.title(\"Flipper Length vs Body Mass by Species\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nimport os\n\n# --- Detect if in Jupyter Notebook ---\ntry:\n    shell = get_ipython().__class__.__name__\n    if \"ZMQInteractiveShell\" in shell:\n        pio.renderers.default = 'notebook'  # Jupyter Notebook\n    else:\n        pio.renderers.default = 'iframe'    # Other notebook-like interface\nexcept NameError:\n    # Not in Jupyter (likely script or terminal)\n    try:\n        pio.renderers.default = 'browser'\n    except:\n        pio.renderers.default = 'svg'\n\n# --- Load dataset ---\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\n\n# --- Clean data ---\npenguins = penguins[['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].dropna()\n\n# --- Plot 1: Bill Length vs Bill Depth ---\nfig1 = px.scatter(\n    penguins,\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    color='species',\n    title='Bill Length vs Bill Depth by Species',\n    labels={'bill_length_mm': 'Bill Length (mm)', 'bill_depth_mm': 'Bill Depth (mm)'}\n)\n\n# --- Plot 2: Flipper Length by Species (Box Plot) ---\nfig2 = px.box(\n    penguins,\n    x='species',\n    y='flipper_length_mm',\n    color='species',\n    title='Flipper Length by Species',\n    labels={'flipper_length_mm': 'Flipper Length (mm)'}\n)\n\n# --- Plot 3: Flipper Length vs Body Mass ---\nfig3 = px.scatter(\n    penguins,\n    x='flipper_length_mm',\n    y='body_mass_g',\n    color='species',\n    title='Flipper Length vs Body Mass by Species',\n    labels={'flipper_length_mm': 'Flipper Length (mm)', 'body_mass_g': 'Body Mass (g)'}\n)\n\n# --- Show or Save Plots Based on Environment ---\ntry:\n    # Try to show plots interactively\n    fig1.show()\n    fig2.show()\n    fig3.show()\nexcept:\n    # If that fails (e.g., headless), save as HTML\n    print(\"Interactive display failed. Saving plots as HTML...\")\n    fig1.write_html(\"fig1_bill_vs_depth.html\")\n    fig2.write_html(\"fig2_flipper_box.html\")\n    fig3.write_html(\"fig3_flipper_vs_mass.html\")\n    print(\"Plots saved in current directory.\")\n\n\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nfrom IPython.display import HTML, display\n\n# Load and clean data\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\npenguins = penguins[['species', 'bill_length_mm', 'bill_depth_mm']].dropna()\n\n# Create plot\nfig = px.scatter(\n    penguins,\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    color='species',\n    title='Bill Length vs Bill Depth by Species'\n)\n\n# Convert Plotly figure to HTML string\nhtml_plot = pio.to_html(fig, full_html=False, include_plotlyjs='cdn')\n\n# Display using IPython\ndisplay(HTML(html_plot))\n\n\nfig.write_html(\"my_plot.html\")\n#<iframe src=\"my_plot.html\" width=\"100%\" height=\"500px\"></iframe>\n\n# ğŸ“Œ Step 1: Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# ğŸ“Œ Step 2: Load Palmer Penguins Dataset\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\n\n# Drop rows with missing values\npenguins.dropna(inplace=True)\n\n# Display first few rows\npenguins.head()\n\n\n# ğŸ“Œ Step 3: Exploratory Data Analysis (Optional but helpful)\nsns.pairplot(penguins, hue=\"species\")\nplt.suptitle(\"Penguin Feature Distributions by Species\", y=1.02)\nplt.show()\n\n\n","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-how-to-ask-ai-for-visualization-strategy","position":27},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ§  AI Cleaning Philosophy","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-cleaning-philosophy-1","position":28},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ§  AI Cleaning Philosophy","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"Notice how the AI provides not just actions, but rationale for each decision. This builds trust and understanding, making the process educational rather than just automated.","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-cleaning-philosophy-1","position":29},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl2","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-enhanced-data-visualization-1","position":30},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-enhanced-data-visualization-1","position":31},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-engaging-ai-for-strategic-visualization-planning-1","position":32},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-engaging-ai-for-strategic-visualization-planning-1","position":33},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl4":"ğŸ’¬ How to Ask AI for Visualization Strategy","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl4","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-how-to-ask-ai-for-visualization-strategy-1","position":34},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl4":"ğŸ’¬ How to Ask AI for Visualization Strategy","lvl3":"ğŸ¤– Engaging AI for Strategic Visualization Planning","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"Instead of: â€œMake some chartsâ€Try: â€œGiven that I have a classification problem with 3 species and 4 numerical features, what visualization strategy would best reveal class separability and feature relationships?â€\n\nResult: AI provides a strategic framework rather than random charts.\n\n# ğŸ“Œ Step 4: Preprocessing\n# Encode categorical features: 'island', 'sex', and target 'species'\n\nle_species = LabelEncoder()\npenguins['species_label'] = le_species.fit_transform(penguins['species'])\n\nle_island = LabelEncoder()\npenguins['island_label'] = le_island.fit_transform(penguins['island'])\n\nle_sex = LabelEncoder()\npenguins['sex_label'] = le_sex.fit_transform(penguins['sex'])\n\n# Define features and target\nfeatures = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'island_label', 'sex_label']\ntarget = 'species_label'\n\n\n# ğŸ“Œ Step 5: Train-Test Split\nX = penguins[features]\ny = penguins[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n# ğŸ“Œ Step 6: Train Random Forest Classifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n\n# ğŸ“Œ Step 7: Evaluate Model\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=le_species.classes_))\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=le_species.classes_, yticklabels=le_species.classes_)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n\n","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-how-to-ask-ai-for-visualization-strategy-1","position":35},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– AI Pattern Recognition Summary:","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-pattern-recognition-summary","position":36},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¤– AI Pattern Recognition Summary:","lvl2":"ğŸ¨ AI-Enhanced Data Visualization"},"content":"Clear species clustering visible in multiple feature combinations\n\nExcellent linear separability suggests high classification accuracy potential\n\nFlipper length vs body mass shows strongest species separation\n\n# ğŸ“Œ Step 8: Feature Importance\nimportances = model.feature_importances_\nfeature_names = X.columns\n\nplt.figure(figsize=(8, 6))\nsns.barplot(x=importances, y=feature_names)\nplt.title(\"Feature Importances in Penguin Classification\")\nplt.show()\n\n\n","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ai-pattern-recognition-summary","position":37},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ† Key Takeaways and Next Steps"},"type":"lvl2","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-key-takeaways-and-next-steps","position":38},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸ† Key Takeaways and Next Steps"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-key-takeaways-and-next-steps","position":39},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¯ What Youâ€™ve Accomplished","lvl2":"ğŸ† Key Takeaways and Next Steps"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-what-youve-accomplished","position":40},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ¯ What Youâ€™ve Accomplished","lvl2":"ğŸ† Key Takeaways and Next Steps"},"content":"âœ… Your AI Integration Achievements:\n\nMastered AI-enhanced data loading with immediate insights\n\nGenerated comprehensive data profiles using AI assistance\n\nImplemented intelligent data cleaning with AI recommendations\n\nCreated strategic visualizations guided by AI analysis\n\nDiscovered key patterns that will drive successful classification","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-what-youve-accomplished","position":41},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ§  Key AI Integration Principles","lvl2":"ğŸ† Key Takeaways and Next Steps"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-key-ai-integration-principles","position":42},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ§  Key AI Integration Principles","lvl2":"ğŸ† Key Takeaways and Next Steps"},"content":"ğŸ¤ Collaboration over Replacement - AI amplifies human expertise rather than replacing it\n\nğŸ“Š Data-Driven Decisions - Let AI analyze patterns, humans interpret context\n\nğŸ”„ Iterative Improvement - Use AI feedback to refine your approach\n\nğŸ“ˆ Scalable Methods - Develop reusable AI-assisted workflows\n\nğŸ¯ Goal-Oriented - Align AI assistance with business objectives","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-key-ai-integration-principles","position":43},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸš€ Ready Mission Assignment 3: Data Interpretation"},"type":"lvl2","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ready-mission-assignment-3-data-interpretation","position":44},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl2":"ğŸš€ Ready Mission Assignment 3: Data Interpretation"},"content":"","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-ready-mission-assignment-3-data-interpretation","position":45},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ–ï¸ Achievement Unlocked!","lvl2":"ğŸš€ Ready Mission Assignment 3: Data Interpretation"},"type":"lvl3","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-achievement-unlocked","position":46},{"hierarchy":{"lvl1":"Mission Assignment 2 - Prediction and Machine Learning","lvl3":"ğŸ–ï¸ Achievement Unlocked!","lvl2":"ğŸš€ Ready Mission Assignment 3: Data Interpretation"},"content":"Congratulations! Youâ€™ve completed Prediction and Machine Learning!\n\nIn the next section, youâ€™ll learn to:\n\nBuild and train classification models with AI guidance\n\nOptimize model performance using AI recommendations\n\nDeploy your trained models for real-world predictions\n\nEvaluate and interpret results with AI assistance\n\nNote: Continue to Misison Assignment 3 to become an â€˜AI Model Builderâ€™ and continue your journey toward an AI Integration Spceialist!","type":"content","url":"/notebooks/mission-assignment-2-prediction-and-machine-learni#id-achievement-unlocked","position":47},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements"},"type":"lvl1","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu","position":0},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements"},"content":"","type":"content","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu","position":1},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸ“Š Visual Data Recap"},"type":"lvl2","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-visual-data-recap","position":2},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸ“Š Visual Data Recap"},"content":"The scatter plot shows distinct clusters of penguin speciesâ€”Adelie (blue), Gentoo (orange), and Chinstrap (green)â€”based on their bill length and depth. These physical traits vary systematically across species.","type":"content","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-visual-data-recap","position":3},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸ§ Ecological Significance"},"type":"lvl2","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-ecological-significance","position":4},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸ§ Ecological Significance"},"content":"Bill morphology is linked to diet and foraging behavior.Gentoo penguins, with longer and shallower bills, tend to forage in deeper waters and consume larger prey like fish.Adelie penguins, with shorter and deeper bills, often feed on krill and smaller marine organisms closer to shore.\n\nThese differences reflect adaptations to specific ecological niches, shaped by the availability of food and habitat conditions in their respective environments.","type":"content","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-ecological-significance","position":5},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸŒ¡ï¸ Environmental Implications"},"type":"lvl2","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-environmental-implications","position":6},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸŒ¡ï¸ Environmental Implications"},"content":"Climate change and ocean warming can alter prey distribution and abundance.Penguins may face pressure to adapt their foraging strategies, which could eventually influence bill morphology over generations.\n\nHabitat shiftsâ€”such as changes in sea ice coverage or ocean currentsâ€”may affect which species thrive in certain regions.The physical traits shown in the plot could serve as indicators of how well each species is suited to changing conditions.","type":"content","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-environmental-implications","position":7},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸ” Big Picture Insight"},"type":"lvl2","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-big-picture-insight","position":8},{"hierarchy":{"lvl1":"ğŸŒ Environmental Interpretation of Penguin Bill Measurements","lvl2":"ğŸ” Big Picture Insight"},"content":"The variation in bill measurements across species is not just a taxonomic distinctionâ€”it reflects evolutionary responses to environmental pressures.Monitoring these traits over time can help scientists:\n\nTrack ecological changes in penguin habitats\n\nPredict species vulnerability to climate shifts\n\nInform conservation strategies based on morphological and behavioral adaptability\n\nSource: Project Pythia â€“ Chapter 2: Prediction & Machine Learning","type":"content","url":"/notebooks/mission-assignment-3-data-interpretation-and-commu#id-big-picture-insight","position":9},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0).\n\nEffectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:  \n\n\n\nğŸ“š See the \n\nCookbook Contributorâ€™s Guide for step-by-step instructions on how to create your new Cookbook and get it hosted on the \n\nPythia Cookbook Gallery!","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"How to Cite This Cookbook","lvl2":"ğŸ§ª Running the Notebooks"},"type":"lvl2","url":"/notebooks/how-to-cite#id-running-the-notebooks","position":2},{"hierarchy":{"lvl1":"How to Cite This Cookbook","lvl2":"ğŸ§ª Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/notebooks/how-to-cite#id-running-the-notebooks","position":3},{"hierarchy":{"lvl1":"How to Cite This Cookbook","lvl3":"ğŸš€ Running on Binder","lvl2":"ğŸ§ª Running the Notebooks"},"type":"lvl3","url":"/notebooks/how-to-cite#id-running-on-binder","position":4},{"hierarchy":{"lvl1":"How to Cite This Cookbook","lvl3":"ğŸš€ Running on Binder","lvl2":"ğŸ§ª Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through \n\nBinder, which enables the execution of a \n\nJupyter Book in the cloud. The details of how this works are not important for now. All you need to know is how to launch a Pythia Cookbook chapter via Binder.\n\nSimply navigate your mouse to the top right corner of the book chapter you are viewing and click on the ğŸš€ rocket ship icon, and be sure to select â€œlaunch Binderâ€. After a moment you should be presented with a notebook that you can interact with. Youâ€™ll be able to execute and even change the example programs. Youâ€™ll see that the code cells have no output at first, until you execute them by pressing {kbd}Shift+Enter.\n\nğŸ“– Complete details on how to interact with a live Jupyter notebook are described in \n\nGetting Started with Jupyter.\n\nâš ï¸ Note: Not all Cookbook chapters are executable. If you do not see the rocket ship icon, such as on this page, you are not viewing an executable book chapter.","type":"content","url":"/notebooks/how-to-cite#id-running-on-binder","position":5},{"hierarchy":{"lvl1":"How to Cite This Cookbook","lvl3":"ğŸ–¥ï¸ Running on Your Own Machine","lvl2":"ğŸ§ª Running the Notebooks"},"type":"lvl3","url":"/notebooks/how-to-cite#id-running-on-your-own-machine","position":6},{"hierarchy":{"lvl1":"How to Cite This Cookbook","lvl3":"ğŸ–¥ï¸ Running on Your Own Machine","lvl2":"ğŸ§ª Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace â€œcookbook-exampleâ€ with the title of your cookbooks)# 1. Clone the repository\ngit clone https://github.com/ProjectPythia/cookbook-example.git\n\n# 2. Move into the directory\ncd cookbook-example\n\n# 3. Create and activate your conda environment\nconda env create -f environment.yml\nconda activate cookbook-example\n\n# 4. Start JupyterLab\ncd notebooks/\njupyter lab","type":"content","url":"/notebooks/how-to-cite#id-running-on-your-own-machine","position":7}]}