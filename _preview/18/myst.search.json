{"version":"1","records":[{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nSee the \n\nCookbook Contributor’s Guide for step-by-step instructions on how to create your new Cookbook and get it hosted on the \n\nPythia Cookbook Gallery!\n\nThis Project Pythia Cookbook covers ... (replace ... with the main subject of your cookbook ... e.g., working with radar data in Python)","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Enhancing Algorithmic Literacy Among Vulnerable Populations through Geoscience Applications"},"type":"lvl2","url":"/#enhancing-algorithmic-literacy-among-vulnerable-populations-through-geoscience-applications","position":2},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Enhancing Algorithmic Literacy Among Vulnerable Populations through Geoscience Applications"},"content":"Imagine a community-based geoscience project where local learners explore biodiversity through a dataset of penguin species.\n\nIn the geoscience community, algorithm literacy is more than technical fluency—it’s a pathway to justice. Vulnerable populations often bear the brunt of environmental decisions shaped by opaque data systems. To shift this paradigm, we must equip these communities not only with knowledge, but with agency.\n\nEnter the AI teammate:  not as a distant tool, but as a responsive partner! Through explicit AI prompts, learners can engage in targeted, conversational learning that breaks down complex algorithmic concepts into accessible, actionable insights. These prompts serve as microburst upskilling lessons--short, focused interactions where AI explains cocepts like correlations, classification, and feature importance as plain language.\n\nVulnerable populations, often excluded from technical discourse, now gain the tools to explore, question, and interpret data that mirrors real-world ecological systems - tailored to real-world geoscience challenges.\n\nBy embedding microburst upskilling into daily workflows and community initiatives, we create rapid, scalable opportunities for learning. These short, focused interactions with AI empower users to ask better questions, challenge assumptions, and co-create solutions. The result? A growing network of algorithm-literate individuals who can actively participate in—and shape—their own liberation.\n\nLet us reimagine algorithm literacy not as a distant goal, but as a daily practice. With AI as a teammate and microburst learning as our method, we can build a geoscience future that is inclusive, transparent, and driven by the voices that matter most.","type":"content","url":"/#enhancing-algorithmic-literacy-among-vulnerable-populations-through-geoscience-applications","position":3},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Authors"},"content":"Lead Author, \n\nFirst Author, \n\nSecond Author, \n\nThird Author","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Structure"},"content":"(State one or more sections that will comprise the notebook. E.g., This cookbook is broken up into two main sections - “Foundations” and “Example Workflows.” Then, describe each section below.)","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. “Foundations” )","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":10},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Section 1 ( Replace with the title of this section, e.g. “Foundations” )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"The foundational content includes ... \")","type":"content","url":"/#section-1-replace-with-the-title-of-this-section-e-g-foundations","position":11},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. “Example workflows” )","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":12},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Section 2 ( Replace with the title of this section, e.g. “Example workflows” )","lvl2":"Structure"},"content":"(Add content for this section, e.g., \"Example workflows include ... \")","type":"content","url":"/#section-2-replace-with-the-title-of-this-section-e-g-example-workflows","position":13},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\n(Replace “cookbook-example” with the title of your cookbooks)\n\nClone the https://github.com/ProjectPythia/cookbook-example repository: git clone https://github.com/ProjectPythia/cookbook-example.git\n\nMove into the cookbook-example directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-example\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Conclusion","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#conclusion","position":20},{"hierarchy":{"lvl1":"A Simplified Data Analysis Using an AI Teammate Exploration Cookbook","lvl3":"Conclusion","lvl2":"Running the Notebooks"},"content":"This project demonstrates that data science is an accessible and impactful discipline that can be applied across a wide range of fields, including scientific research, industrial operations, government, private industry, and manufacturing/production. By emphasizing practical experience, task-specific prompts, and reproducible workflows, we highlight the importance of learning by doing—allowing participants to track progress through cumulative task-specific badges that culminate in context-based credentials.\n\nA key takeaway from our approach is that no prior coding experience is required to engage meaningfully with data science. Through community development and upskilling, individuals can bridge the gap between technical barriers and real-world applications, empowering broader participation in the data-driven economy.\n\nUltimately, this project underscores a democratized vision of data science—where anyone can learn, practice, and contribute—by fostering inclusive learning environments, sharing reproducible tools, and promoting AI-integrated pathways such as the AI integration specialist badge. We hope this work serves as a foundation for scalable, interdisciplinary engagement and sustainable growth in digital literacy and data fluency.","type":"content","url":"/#conclusion","position":21},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/notebooks/ftuluri01","position":0},{"hierarchy":{"lvl1":""},"content":"import pandas as pd\n\n# GitHub URL for the CSV file (raw format)\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n\n# Load the dataset into a pandas DataFrame\npenguins = pd.read_csv(url)\n\n# Display the variable (column) names\nprint(\"Variable (column) names in the Palmer Penguins dataset:\")\nprint(penguins.columns.tolist())\n\npip install plotly\n\nimport plotly\n\nimport pandas as pd\n\n# GitHub URL for the CSV file (raw format)\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n\n# Load the dataset into a pandas DataFrame\npenguins = pd.read_csv(url)\n\n# Display the variable (column) names\nprint(\"Variable (column) names in the Palmer Penguins dataset:\")\nprint(penguins.columns.tolist())\n\n\nprint(penguins.head(10))\n\ncolumn_names_list = penguins.columns.tolist()\nprint(\"Column names (as a list using .tolist()):\")\nprint(column_names_list)\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load dataset\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\n\n# Drop rows with missing values in selected columns\npenguins = penguins[['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].dropna()\n\n# Set style\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# 1. Scatter Plot: Bill Length vs Bill Depth\nplt.figure(figsize=(8, 6))\nfor species in penguins['species'].unique():\n    subset = penguins[penguins['species'] == species]\n    plt.scatter(subset['bill_length_mm'], subset['bill_depth_mm'], label=species, alpha=0.7)\nplt.xlabel(\"Bill Length (mm)\")\nplt.ylabel(\"Bill Depth (mm)\")\nplt.title(\"Bill Length vs Bill Depth by Species\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# 2. Box Plot: Flipper Length by Species\nplt.figure(figsize=(8, 6))\npenguins.boxplot(column='flipper_length_mm', by='species')\nplt.title(\"Flipper Length by Species\")\nplt.suptitle('')\nplt.xlabel(\"Species\")\nplt.ylabel(\"Flipper Length (mm)\")\nplt.tight_layout()\nplt.show()\n\n# 3. Scatter Plot: Flipper Length vs Body Mass\nplt.figure(figsize=(8, 6))\nfor species in penguins['species'].unique():\n    subset = penguins[penguins['species'] == species]\n    plt.scatter(subset['flipper_length_mm'], subset['body_mass_g'], label=species, alpha=0.7)\nplt.xlabel(\"Flipper Length (mm)\")\nplt.ylabel(\"Body Mass (g)\")\nplt.title(\"Flipper Length vs Body Mass by Species\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nimport os\n\n# --- Detect if in Jupyter Notebook ---\ntry:\n    shell = get_ipython().__class__.__name__\n    if \"ZMQInteractiveShell\" in shell:\n        pio.renderers.default = 'notebook'  # Jupyter Notebook\n    else:\n        pio.renderers.default = 'iframe'    # Other notebook-like interface\nexcept NameError:\n    # Not in Jupyter (likely script or terminal)\n    try:\n        pio.renderers.default = 'browser'\n    except:\n        pio.renderers.default = 'svg'\n\n# --- Load dataset ---\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\n\n# --- Clean data ---\npenguins = penguins[['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].dropna()\n\n# --- Plot 1: Bill Length vs Bill Depth ---\nfig1 = px.scatter(\n    penguins,\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    color='species',\n    title='Bill Length vs Bill Depth by Species',\n    labels={'bill_length_mm': 'Bill Length (mm)', 'bill_depth_mm': 'Bill Depth (mm)'}\n)\n\n# --- Plot 2: Flipper Length by Species (Box Plot) ---\nfig2 = px.box(\n    penguins,\n    x='species',\n    y='flipper_length_mm',\n    color='species',\n    title='Flipper Length by Species',\n    labels={'flipper_length_mm': 'Flipper Length (mm)'}\n)\n\n# --- Plot 3: Flipper Length vs Body Mass ---\nfig3 = px.scatter(\n    penguins,\n    x='flipper_length_mm',\n    y='body_mass_g',\n    color='species',\n    title='Flipper Length vs Body Mass by Species',\n    labels={'flipper_length_mm': 'Flipper Length (mm)', 'body_mass_g': 'Body Mass (g)'}\n)\n\n# --- Show or Save Plots Based on Environment ---\ntry:\n    # Try to show plots interactively\n    fig1.show()\n    fig2.show()\n    fig3.show()\nexcept:\n    # If that fails (e.g., headless), save as HTML\n    print(\"Interactive display failed. Saving plots as HTML...\")\n    fig1.write_html(\"fig1_bill_vs_depth.html\")\n    fig2.write_html(\"fig2_flipper_box.html\")\n    fig3.write_html(\"fig3_flipper_vs_mass.html\")\n    print(\"Plots saved in current directory.\")\n\n\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nfrom IPython.display import HTML, display\n\n# Load and clean data\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\npenguins = penguins[['species', 'bill_length_mm', 'bill_depth_mm']].dropna()\n\n# Create plot\nfig = px.scatter(\n    penguins,\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    color='species',\n    title='Bill Length vs Bill Depth by Species'\n)\n\n# Convert Plotly figure to HTML string\nhtml_plot = pio.to_html(fig, full_html=False, include_plotlyjs='cdn')\n\n# Display using IPython\ndisplay(HTML(html_plot))\n\n\nfig.write_html(\"my_plot.html\")\n#<iframe src=\"my_plot.html\" width=\"100%\" height=\"500px\"></iframe>\n\n# 📌 Step 1: Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# 📌 Step 2: Load Palmer Penguins Dataset\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\n\n# Drop rows with missing values\npenguins.dropna(inplace=True)\n\n# Display first few rows\npenguins.head()\n\n\n# 📌 Step 3: Exploratory Data Analysis (Optional but helpful)\nsns.pairplot(penguins, hue=\"species\")\nplt.suptitle(\"Penguin Feature Distributions by Species\", y=1.02)\nplt.show()\n\n\n# 📌 Step 4: Preprocessing\n# Encode categorical features: 'island', 'sex', and target 'species'\n\nle_species = LabelEncoder()\npenguins['species_label'] = le_species.fit_transform(penguins['species'])\n\nle_island = LabelEncoder()\npenguins['island_label'] = le_island.fit_transform(penguins['island'])\n\nle_sex = LabelEncoder()\npenguins['sex_label'] = le_sex.fit_transform(penguins['sex'])\n\n# Define features and target\nfeatures = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'island_label', 'sex_label']\ntarget = 'species_label'\n\n\n# 📌 Step 5: Train-Test Split\nX = penguins[features]\ny = penguins[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n# 📌 Step 6: Train Random Forest Classifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n\n# 📌 Step 7: Evaluate Model\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=le_species.classes_))\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=le_species.classes_, yticklabels=le_species.classes_)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n\n# 📌 Step 8: Feature Importance\nimportances = model.feature_importances_\nfeature_names = X.columns\n\nplt.figure(figsize=(8, 6))\nsns.barplot(x=importances, y=feature_names)\nplt.title(\"Feature Importances in Penguin Classification\")\nplt.show()\n","type":"content","url":"/notebooks/ftuluri01","position":1},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡"},"type":"lvl1","url":"/notebooks/overview","position":0},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡"},"content":"Your Interactive Journey from Data Novice to AI Integration Expert\n\n🎯 Your Mission\n\nWelcome to your AI integration journey! Using the adorable Palmer Penguins dataset, you’ll master the complete data science workflow. By the end of this cookbook, you’ll have the skills and confidence to integrate AI into your own projects and workflows. Ready to become an AI Integration Expert?","type":"content","url":"/notebooks/overview","position":1},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl3":"📊 Progress Tracker"},"type":"lvl3","url":"/notebooks/overview#id-progress-tracker","position":2},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl3":"📊 Progress Tracker"},"content":"Progress \n\n0/4 Complete\n\n\n\n🎯 Current Status: Getting Started","type":"content","url":"/notebooks/overview#id-progress-tracker","position":3},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl3":"🗺️ Learning Path"},"type":"lvl3","url":"/notebooks/overview#id-learning-path","position":4},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl3":"🗺️ Learning Path"},"content":"","type":"content","url":"/notebooks/overview#id-learning-path","position":5},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"🎯 Section 1: Project Overview","lvl3":"🗺️ Learning Path"},"type":"lvl4","url":"/notebooks/overview#id-section-1-project-overview","position":6},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"🎯 Section 1: Project Overview","lvl3":"🗺️ Learning Path"},"content":"Understanding the Palmer Penguins Challenge\n\nWhat You’ll Accomplish:\n\nMeet our penguin friends (Adelie, Chinstrap, Gentoo)\n\nUnderstand the business problem: species classification\n\nReview the complete data science workflow\n\nSet your learning objectives\n\nReward: ⭐ Data Science Detective BadgeTime: ⏱️ 15 minutes\n\n[ ] Complete\n\n📖 Section Details\n\nLearn about our dataset, goals, and the AI workflow we’ll master together. This foundational section sets the stage for your entire learning journey.\n\nKey Concepts:\n\nData Science Methodology\n\nProblem Definition\n\nSuccess Metrics","type":"content","url":"/notebooks/overview#id-section-1-project-overview","position":7},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"🔍 Section 2: Data Acquisition & Cleaning","lvl3":"🗺️ Learning Path"},"type":"lvl4","url":"/notebooks/overview#id-section-2-data-acquisition-cleaning","position":8},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"🔍 Section 2: Data Acquisition & Cleaning","lvl3":"🗺️ Learning Path"},"content":"Getting Your Hands Dirty with Real Data\n\nWhat You’ll Accomplish:\n\nInstall and import the palmerpenguins package\n\nLoad the dataset and explore its structure\n\nIdentify and handle missing values\n\nPerform basic data quality checks\n\nCreate a clean dataset ready for analysis\n\nReward: ⭐ Data Cleaning Specialist CertificateTime: ⏱️ 45 minutes\n\n[ ] Complete\n\n🔧 Section Details\n\nMaster the art of loading, exploring, and cleaning messy real-world data. You’ll learn essential data preprocessing skills.\n\nKey Skills:\n\nData Loading Techniques\n\nMissing Value Handling\n\nData Quality Assessment","type":"content","url":"/notebooks/overview#id-section-2-data-acquisition-cleaning","position":9},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"📊 Section 3: Data Visualization & Exploration","lvl3":"🗺️ Learning Path"},"type":"lvl4","url":"/notebooks/overview#id-section-3-data-visualization-exploration","position":10},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"📊 Section 3: Data Visualization & Exploration","lvl3":"🗺️ Learning Path"},"content":"Making Data Tell Its Story\n\nWhat You’ll Accomplish:\n\nCreate species distribution plots\n\nBuild correlation heatmaps\n\nDesign interactive scatter plots\n\nCraft publication-ready visualizations\n\nDiscover surprising patterns in penguin behavior\n\nReward: ⭐ Visualization Virtuoso MedalTime: ⏱️ 60 minutes\n\n[ ] Complete\n\n📈 Section Details\n\nCreate compelling visualizations that reveal hidden patterns and insights. Transform raw data into meaningful stories.\n\nVisualization Types:\n\nStatistical Distributions\n\nCorrelation Analysis\n\nInteractive Plots","type":"content","url":"/notebooks/overview#id-section-3-data-visualization-exploration","position":11},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"🧠 Section 4: AI Model Building & Prediction","lvl3":"🗺️ Learning Path"},"type":"lvl4","url":"/notebooks/overview#id-section-4-ai-model-building-prediction","position":12},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl4":"🧠 Section 4: AI Model Building & Prediction","lvl3":"🗺️ Learning Path"},"content":"Building Your First AI Classification System\n\nWhat You’ll Accomplish:\n\nSplit data into training and testing sets\n\nTrain your first decision tree classifier\n\nCompare multiple AI algorithms\n\nOptimize model performance\n\nDeploy your AI system for real predictions\n\nReward: ⭐ AI Integration Master CertificationTime: ⏱️ 90 minutes\n\n[ ] Complete\n\n🤖 Section Details\n\nTrain machine learning models to automatically classify penguin species. Build your first complete AI system from scratch.\n\nML Techniques:\n\nTrain-Test Splitting\n\nAlgorithm Comparison\n\nPerformance Optimization\n\n","type":"content","url":"/notebooks/overview#id-section-4-ai-model-building-prediction","position":13},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl2":"🎉 Congratulations! 🏆"},"type":"lvl2","url":"/notebooks/overview#id-congratulations","position":14},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl2":"🎉 Congratulations! 🏆"},"content":"You are now AI Integration Certified!\n\nYou’ve mastered the complete data science workflow and are ready to integrate AI into your own projects. Share your achievement and help others on their AI journey!","type":"content","url":"/notebooks/overview#id-congratulations","position":15},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl3":"🚀 Ready to Begin?","lvl2":"🎉 Congratulations! 🏆"},"type":"lvl3","url":"/notebooks/overview#id-ready-to-begin","position":16},{"hierarchy":{"lvl1":"⚡ AI Integration Cookbook ⚡","lvl3":"🚀 Ready to Begin?","lvl2":"🎉 Congratulations! 🏆"},"content":"📚 Prerequisites\n\nBasic Python knowledge (helpful but not required)\n\nJupyter Notebook environment\n\nCuriosity and willingness to learn!\n\n🎁 What You’ll Get\n\nHands-on experience with real data\n\nReusable code templates\n\nConfidence to tackle your own AI projects\n```{button-link} #\n:color: primary\n:expand:\n:click-parent:\n\n🐧 Start Your Penguin Adventure!\n\n💡 Pro Tip\n\nClick the checkboxes as you complete each section to track your progress and unlock achievement badges!","type":"content","url":"/notebooks/overview#id-ready-to-begin","position":17},{"hierarchy":{"lvl1":"🐧 Palmer Penguins: A Data Science Recipe"},"type":"lvl1","url":"/notebooks/palmer-penguins-recipe","position":0},{"hierarchy":{"lvl1":"🐧 Palmer Penguins: A Data Science Recipe"},"content":"This notebook demonstrates how to explore and analyze the Palmer Penguins dataset using Pandas and Matplotlib. You’ll learn how to clean data, visualize relationships, and prepare for modeling.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the dataset\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\npenguins = pd.read_csv(url)\npenguins.head()\n\n","type":"content","url":"/notebooks/palmer-penguins-recipe","position":1},{"hierarchy":{"lvl1":"🐧 Palmer Penguins: A Data Science Recipe","lvl2":"🧹 Step 1: Data Cleaning"},"type":"lvl2","url":"/notebooks/palmer-penguins-recipe#id-step-1-data-cleaning","position":2},{"hierarchy":{"lvl1":"🐧 Palmer Penguins: A Data Science Recipe","lvl2":"🧹 Step 1: Data Cleaning"},"content":"We’ll check for missing values and clean the dataset by removing or filling them.\n\npenguins.info()\npenguins.isnull().sum()\n\n# Drop rows with missing values\npenguins_clean = penguins.dropna()\npenguins_clean.shape\n\n","type":"content","url":"/notebooks/palmer-penguins-recipe#id-step-1-data-cleaning","position":3},{"hierarchy":{"lvl1":"🐧 Palmer Penguins: A Data Science Recipe","lvl2":"📊 Step 2: Visualizations with Matplotlib"},"type":"lvl2","url":"/notebooks/palmer-penguins-recipe#id-step-2-visualizations-with-matplotlib","position":4},{"hierarchy":{"lvl1":"🐧 Palmer Penguins: A Data Science Recipe","lvl2":"📊 Step 2: Visualizations with Matplotlib"},"content":"Let’s visualize the distribution of penguin species and relationships between features.\n\n# Bar chart of species count\npenguins_clean['species'].value_counts().plot(kind='bar', title='Species Count')\nplt.xlabel('Species')\nplt.ylabel('Count')\nplt.show()\n\n# Scatter plot: Bill Length vs Bill Depth\nfor species in penguins_clean['species'].unique():\n    subset = penguins_clean[penguins_clean['species'] == species]\n    plt.scatter(subset['bill_length_mm'], subset['bill_depth_mm'], label=species)\n\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\nplt.title('Bill Length vs Bill Depth by Species')\nplt.legend()\nplt.show()","type":"content","url":"/notebooks/palmer-penguins-recipe#id-step-2-visualizations-with-matplotlib","position":5}]}